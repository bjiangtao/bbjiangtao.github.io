<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>elasticsearch的读写原理</title>
      <link href="/2020/05/04/%E5%AD%A6%E4%B9%A0/elasticsearch%E7%9A%84%E8%AF%BB%E5%86%99%E5%8E%9F%E7%90%86/"/>
      <url>/2020/05/04/%E5%AD%A6%E4%B9%A0/elasticsearch%E7%9A%84%E8%AF%BB%E5%86%99%E5%8E%9F%E7%90%86/</url>
      
        <content type="html"><![CDATA[<p><img src="http://assets.processon.com/chart_image/5eaefc8e1e085346f73106ac.png" alt="avatar"></p>]]></content>
      
      
      <categories>
          
          <category> elasticsearch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> elasticsearch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>elasticsearch优化查询</title>
      <link href="/2020/05/04/%E5%AD%A6%E4%B9%A0/elasticsearch%E4%BC%98%E5%8C%96%E6%9F%A5%E8%AF%A2/"/>
      <url>/2020/05/04/%E5%AD%A6%E4%B9%A0/elasticsearch%E4%BC%98%E5%8C%96%E6%9F%A5%E8%AF%A2/</url>
      
        <content type="html"><![CDATA[<p>比较依赖 os cache，更多的segment file 能加载更多到内存，就会更快</p>]]></content>
      
      
      <categories>
          
          <category> elasticsearch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> elasticsearch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>elasticsearch的架构</title>
      <link href="/2020/05/04/%E5%AD%A6%E4%B9%A0/elasticsearch%E7%9A%84%E6%9E%B6%E6%9E%84/"/>
      <url>/2020/05/04/%E5%AD%A6%E4%B9%A0/elasticsearch%E7%9A%84%E6%9E%B6%E6%9E%84/</url>
      
        <content type="html"><![CDATA[<p><img src="http://assets.processon.com/chart_image/5eae79df5653bb6efc7e11b6.png" alt="avatar"></p>]]></content>
      
      
      <categories>
          
          <category> elasticsearch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> elasticsearch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>设计mq</title>
      <link href="/2020/05/03/%E5%AD%A6%E4%B9%A0/%E8%AE%BE%E8%AE%A1mq/"/>
      <url>/2020/05/03/%E5%AD%A6%E4%B9%A0/%E8%AE%BE%E8%AE%A1mq/</url>
      
        <content type="html"><![CDATA[<p>参考kafka的设计</p><p>1.可伸缩 partition和replication的概念</p><p>2.持久化</p><p>3.不丢失</p><p>4.高可用 leader follower的概念</p>]]></content>
      
      
      <categories>
          
          <category> mq </category>
          
      </categories>
      
      
        <tags>
            
            <tag> mq </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>mq的顺序性</title>
      <link href="/2020/05/03/%E5%AD%A6%E4%B9%A0/mq%E7%9A%84%E9%A1%BA%E5%BA%8F%E6%80%A7/"/>
      <url>/2020/05/03/%E5%AD%A6%E4%B9%A0/mq%E7%9A%84%E9%A1%BA%E5%BA%8F%E6%80%A7/</url>
      
        <content type="html"><![CDATA[<p>所有消息都有序，必须只能由单线程去消费执行</p><p>消息按照key分类，保证key有序，可以通过业务去创建内存队列，通过不同内存队列来保证有序</p>]]></content>
      
      
      <categories>
          
          <category> mq </category>
          
      </categories>
      
      
        <tags>
            
            <tag> mq </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>mq的可靠性传输</title>
      <link href="/2020/05/03/%E5%AD%A6%E4%B9%A0/mq%E7%9A%84%E5%8F%AF%E9%9D%A0%E6%80%A7%E4%BC%A0%E8%BE%93/"/>
      <url>/2020/05/03/%E5%AD%A6%E4%B9%A0/mq%E7%9A%84%E5%8F%AF%E9%9D%A0%E6%80%A7%E4%BC%A0%E8%BE%93/</url>
      
        <content type="html"><![CDATA[<h1 id="rabbitmq可能存在的丢失的数据问题"><a href="#rabbitmq可能存在的丢失的数据问题" class="headerlink" title="rabbitmq可能存在的丢失的数据问题"></a>rabbitmq可能存在的丢失的数据问题</h1><h2 id="往队列里面发消息保证不丢的2中方案"><a href="#往队列里面发消息保证不丢的2中方案" class="headerlink" title="往队列里面发消息保证不丢的2中方案"></a>往队列里面发消息保证不丢的2中方案</h2><p>事务提交消息模式</p><p>confirm 回调机制</p><h2 id="mq丢失"><a href="#mq丢失" class="headerlink" title="mq丢失"></a>mq丢失</h2><p>设置队列持久化</p><h2 id="消费者消息丢失"><a href="#消费者消息丢失" class="headerlink" title="消费者消息丢失"></a>消费者消息丢失</h2><p>取消autoAck机制，由程序执行完毕再进行ACK</p><h1 id="kafka可能丢消息的处理场景"><a href="#kafka可能丢消息的处理场景" class="headerlink" title="kafka可能丢消息的处理场景"></a>kafka可能丢消息的处理场景</h1><h2 id="消费者消息丢失-1"><a href="#消费者消息丢失-1" class="headerlink" title="消费者消息丢失"></a>消费者消息丢失</h2><p>取消autoACK机制，由程序手动ACK</p><h2 id="队列本身丢失"><a href="#队列本身丢失" class="headerlink" title="队列本身丢失"></a>队列本身丢失</h2><p>topic的replication的数量 大于1个</p><p>服务端设置最小follower 保持联系的参数，至少是1个</p><p>producer端设置  retire 无限尝试、设置 ack 为全部follower确认</p>]]></content>
      
      
      <categories>
          
          <category> mq </category>
          
      </categories>
      
      
        <tags>
            
            <tag> mq </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>mq的幂等性</title>
      <link href="/2020/05/03/%E5%AD%A6%E4%B9%A0/mq%E7%9A%84%E5%B9%82%E7%AD%89%E6%80%A7/"/>
      <url>/2020/05/03/%E5%AD%A6%E4%B9%A0/mq%E7%9A%84%E5%B9%82%E7%AD%89%E6%80%A7/</url>
      
        <content type="html"><![CDATA[<p>mq本身是不会保证幂等性的，是由本身的业务系统来处理幂等性的。</p><p>重复现象发生的原因？当业务系统重启，此时一条消息正在消费仍未ACK，就会出现一条消息消费2次的现象。</p><p>一条消息就一次ACK机制，业务系统的重启，添加未处理的机制。数据库唯一键约束，或者缓存约束。</p>]]></content>
      
      
      <categories>
          
          <category> mq </category>
          
      </categories>
      
      
        <tags>
            
            <tag> mq </tag>
            
            <tag> 幂等性 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>mq的高可用</title>
      <link href="/2020/05/03/%E5%AD%A6%E4%B9%A0/mq%E7%9A%84%E9%AB%98%E5%8F%AF%E7%94%A8/"/>
      <url>/2020/05/03/%E5%AD%A6%E4%B9%A0/mq%E7%9A%84%E9%AB%98%E5%8F%AF%E7%94%A8/</url>
      
        <content type="html"><![CDATA[<h1 id="rabbitmq的高可用"><a href="#rabbitmq的高可用" class="headerlink" title="rabbitmq的高可用"></a>rabbitmq的高可用</h1><h2 id="镜像集群模式"><a href="#镜像集群模式" class="headerlink" title="镜像集群模式"></a>镜像集群模式</h2><p>写消息的过程，把消息写到集群中的每个节点；消费消息的时候，可以在任意一个节点去消费消息。</p><h1 id="kafka的高可用"><a href="#kafka的高可用" class="headerlink" title="kafka的高可用"></a>kafka的高可用</h1><p><img src="http://assets.processon.com/chart_image/5eab98e27d9c0869dab48bd0.png" alt="avatar"></p>]]></content>
      
      
      <categories>
          
          <category> mq </category>
          
      </categories>
      
      
        <tags>
            
            <tag> mq </tag>
            
            <tag> 高可用 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>mq的技术选型</title>
      <link href="/2020/05/03/%E5%AD%A6%E4%B9%A0/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E7%9A%84%E9%80%89%E5%9E%8B/"/>
      <url>/2020/05/03/%E5%AD%A6%E4%B9%A0/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E7%9A%84%E9%80%89%E5%9E%8B/</url>
      
        <content type="html"><![CDATA[<h2 id="组件带来的优点"><a href="#组件带来的优点" class="headerlink" title="组件带来的优点"></a>组件带来的优点</h2><p>解耦、异步、削峰</p><h2 id="组件带来的问题"><a href="#组件带来的问题" class="headerlink" title="组件带来的问题"></a>组件带来的问题</h2><p>XXX</p><h2 id="业务需要的场景"><a href="#业务需要的场景" class="headerlink" title="业务需要的场景"></a>业务需要的场景</h2><p>XXX</p><h2 id="组件各种实现的差别"><a href="#组件各种实现的差别" class="headerlink" title="组件各种实现的差别"></a>组件各种实现的差别</h2><p>rabbitMq、rocketMq、kafka</p>]]></content>
      
      
      <categories>
          
          <category> mq </category>
          
      </categories>
      
      
        <tags>
            
            <tag> mq </tag>
            
            <tag> 技术选型 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Redis线程模型</title>
      <link href="/2020/05/02/%E5%AD%A6%E4%B9%A0/Redis%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B/"/>
      <url>/2020/05/02/%E5%AD%A6%E4%B9%A0/Redis%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B/</url>
      
        <content type="html"><![CDATA[<p>文件事件处理器由socket、IO多路复用程序、文件事件分派器、事件处理器4个组件构成。</p><p>当客户端连接到服务端，服务端就为客户端创建一个socket的AE_REABLE事件，通过IO多路复用程序，放到队列中，有一个时间分派器组件去处理socket的事件请求，由请求连接处理器，命令执行处理器，命令回复处理器去分别执行对象的请求。其中命令执行处理器，执行完成后，会将返回值和该socket的命令回复处理器相关联，在之后socket的AE_WRITEABLE事件产生后，去获取到该消息的返回。</p>]]></content>
      
      
      <categories>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Redis的高并发和高可用</title>
      <link href="/2020/05/02/%E5%AD%A6%E4%B9%A0/redis%E9%AB%98%E5%B9%B6%E5%8F%91%E5%92%8C%E9%AB%98%E5%8F%AF%E7%94%A8/"/>
      <url>/2020/05/02/%E5%AD%A6%E4%B9%A0/redis%E9%AB%98%E5%B9%B6%E5%8F%91%E5%92%8C%E9%AB%98%E5%8F%AF%E7%94%A8/</url>
      
        <content type="html"><![CDATA[<h1 id="高并发的保证"><a href="#高并发的保证" class="headerlink" title="高并发的保证"></a>高并发的保证</h1><p>Redis主从架构，</p><h1 id="高可用的保证"><a href="#高可用的保证" class="headerlink" title="高可用的保证"></a>高可用的保证</h1><p>Redis 哨兵  sentinal 2版本</p><h1 id="哨兵配置"><a href="#哨兵配置" class="headerlink" title="哨兵配置"></a>哨兵配置</h1><p>1.至少需要3个实例</p><p>2.哨兵+redis主从的部署架构，不会保证Redis零丢失数据，只是保证Redis集群的高可用</p><h2 id="哨兵存在的问题"><a href="#哨兵存在的问题" class="headerlink" title="哨兵存在的问题"></a>哨兵存在的问题</h2><p>1.异步复制导致数据丢失</p><p>2.脑裂，网络异常导致master选取出现问题</p><h2 id="解决异步复制和脑裂导致的数据丢失"><a href="#解决异步复制和脑裂导致的数据丢失" class="headerlink" title="解决异步复制和脑裂导致的数据丢失"></a>解决异步复制和脑裂导致的数据丢失</h2><p>min-slaves-to-write 1</p><p>min-slaves-max-lag 10</p><p>要求至少有1个slave，数据复制和同步的延迟不能超过10秒</p><p>如果说一旦所有的slave，数据复制和同步的延迟都超过了10秒钟，那么这个时候，master就不会再接收任何请求了</p><p>上面两个配置可以减少异步复制和脑裂导致的数据丢失</p><p>（1）减少异步复制的数据丢失</p><p>有了min-slaves-max-lag这个配置，就可以确保说，一旦slave复制数据和ack延时太长，就认为可能master宕机后损失的数据太多了，那么就拒绝写请求，这样可以把master宕机时由于部分数据未同步到slave导致的数据丢失降低的可控范围内</p><p>（2）减少脑裂的数据丢失</p><p>如果一个master出现了脑裂，跟其他slave丢了连接，那么上面两个配置可以确保说，如果不能继续给指定数量的slave发送数据，而且slave超过10秒没有给自己ack消息，那么就直接拒绝客户端的写请求</p><p>这样脑裂后的旧master就不会接受client的新数据，也就避免了数据丢失</p><p>上面的配置就确保了，如果跟任何一个slave丢了连接，在10秒后发现没有slave给自己ack，那么就拒绝新的写请求</p><p>因此在脑裂场景下，最多就丢失10秒的数据</p>]]></content>
      
      
      <categories>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Redis一致性问题</title>
      <link href="/2020/05/02/%E5%AD%A6%E4%B9%A0/Redis%E4%B8%80%E8%87%B4%E6%80%A7%E9%97%AE%E9%A2%98/"/>
      <url>/2020/05/02/%E5%AD%A6%E4%B9%A0/Redis%E4%B8%80%E8%87%B4%E6%80%A7%E9%97%AE%E9%A2%98/</url>
      
        <content type="html"><![CDATA[<p>1.读缓存的时候，先读缓存，缓存为空，在读数据库，取出数据，然后设置缓存</p><p>2.写操作。更新DB，然后删除缓存（保证了强一致性）</p><p>如果需要很强一致性的场景，可以考虑在key加上分布式锁，来保证读和写的串行化！</p>]]></content>
      
      
      <categories>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Redis雪崩和穿透</title>
      <link href="/2020/05/02/%E5%AD%A6%E4%B9%A0/Redis%E9%9B%AA%E5%B4%A9%E5%92%8C%E7%A9%BF%E9%80%8F/"/>
      <url>/2020/05/02/%E5%AD%A6%E4%B9%A0/Redis%E9%9B%AA%E5%B4%A9%E5%92%8C%E7%A9%BF%E9%80%8F/</url>
      
        <content type="html"><![CDATA[<h2 id="1-Redis雪崩的处理方案。发生前、发生中、发生后。"><a href="#1-Redis雪崩的处理方案。发生前、发生中、发生后。" class="headerlink" title="1.Redis雪崩的处理方案。发生前、发生中、发生后。"></a>1.Redis雪崩的处理方案。发生前、发生中、发生后。</h2><p>发生现象，大流量超过Redis负载，Redis宕机</p><p>发生前，保证Redis集群的高可用，主从+哨兵机制，避免Redis全量崩盘</p><p>发生中，限流和降级，保证数据库不挂掉</p><p>发生后，通过redis持久化的数据，重启Redis，快速恢复数据</p><h2 id="2-缓存穿透"><a href="#2-缓存穿透" class="headerlink" title="2.缓存穿透"></a>2.缓存穿透</h2><p>缓存空数据</p><p>布隆过滤器</p><h2 id="3-热点缓存"><a href="#3-热点缓存" class="headerlink" title="3.热点缓存"></a>3.热点缓存</h2><p>如何发现热缓存？</p><p>热缓存的处理方案？</p><p>1.引入本地缓存机制。ehcache或hashMap，直接先从本地查询到了，就不用查询Redis缓存了。</p><p>2.备份热key，不要让key都走到一组Redis上，在多组Redis中都存放一份。</p>]]></content>
      
      
      <categories>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>G1收集器详解</title>
      <link href="/2020/04/29/%E5%AD%A6%E4%B9%A0/G1/"/>
      <url>/2020/04/29/%E5%AD%A6%E4%B9%A0/G1/</url>
      
        <content type="html"><![CDATA[<p>G1垃圾收集器，取消了堆中年轻代和老年代的物理划分，但仍属于分代收集器。G1算法将堆划分为若干个Region区域。其中一部分作用于年轻代，一部分作用于老年代，还有一种专门用于存储大对象的分区。</p><p>几个概念</p><p>三色标记算法，白灰黑。白：对象没有被标记到，标记阶段结束，会被当做垃圾回收掉。灰：对象被标记了，但是它的filed还没有被标记完。黑:对象都别标记了，且它的filed也被标记完了。</p><p>新生代采用复制算法，并行进行收集，收集过程会STW</p><p>老年代回收时同时也会触发年轻代的回收，回收主要分为4个阶段：</p><p>1.初始标记（initial remark  STW）。它标记了从GC Root开始直接可达的对象</p><p>2.并发标记（concurrent mark）。这个标记阶段从GC Root开始对heap中的对象进行标记，标记线程和用户线程并发执行，并且收集各个Region的存活对象信息。</p><p>3.最终标记（remark STW）。标记那些在并发阶段发生变化的对象</p><p>4.复制/清除。（cleanup STW），这个阶段会优先对可回收空间较大的Region进行回收，即为Garbage first</p><p>G1采用的是每次只清理一部分而不是全部的Region的增量式清理，由此来保证每次GC停顿时间不会太长。</p><p>总结如下，G1是逻辑分代不是物理分代，需要知道回收的过程和停顿的阶段。此外还需要知道，G1算法允许通过JVM参数来设置Region大小，范围是1-32M（2的幂次），可以设置期望的最大停顿时间等</p>]]></content>
      
      
      <categories>
          
          <category> java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> jvm </tag>
            
            <tag> 垃圾收集器 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>JVM</title>
      <link href="/2020/04/29/%E5%AD%A6%E4%B9%A0/java%20-%20%E5%89%AF%E6%9C%AC/"/>
      <url>/2020/04/29/%E5%AD%A6%E4%B9%A0/java%20-%20%E5%89%AF%E6%9C%AC/</url>
      
        <content type="html"><![CDATA[<h2 id="1-jvm内存模型"><a href="#1-jvm内存模型" class="headerlink" title="1.jvm内存模型"></a>1.jvm内存模型</h2><h2 id="2-GC流程"><a href="#2-GC流程" class="headerlink" title="2.GC流程"></a>2.GC流程</h2><p>新生代创建对象，新生代区域不够的时候，会触发YGC,此时新生代会触发GC，对象进行清理。根据可达性算法对新生代空间的对象进行标记，通过复制算法进行新生代的对象回收。在多YGC过后，对象经过多次YGC后，然后就可以进行进行对象晋升，把该对象晋升到老年代。多次YGC之后，对象晋升老年代时候发现老年代的内存空间不足，会对老年代进行GC，通过</p><h2 id="3-常见的垃圾回收器"><a href="#3-常见的垃圾回收器" class="headerlink" title="3.常见的垃圾回收器"></a>3.常见的垃圾回收器</h2><p>CMS</p><p>ZGC</p><h2 id="4-G1收集器详解"><a href="#4-G1收集器详解" class="headerlink" title="4.G1收集器详解"></a>4.G1收集器详解</h2><p>G1垃圾收集器，取消了堆中年轻代和老年代的物理划分，但仍属于分代收集器。G1算法将堆划分为若干个Region区域。其中一部分作用于年轻代，一部分作用于老年代，还有一种专门用于存储大对象的分区。</p><p>几个概念</p><p>三色标记算法，白灰黑。白：对象没有被标记到，标记阶段结束，会被当做垃圾回收掉。灰：对象被标记了，但是它的filed还没有被标记完。黑:对象都别标记了，且它的filed也被标记完了。</p><p>新生代采用复制算法，并行进行收集，收集过程会STW</p><p>老年代回收时同时也会触发年轻代的回收，回收主要分为4个阶段：</p><p>1.初始标记（initial remark  STW）。它标记了从GC Root开始直接可达的对象</p><p>2.并发标记（concurrent mark）。这个标记阶段从GC Root开始对heap中的对象进行标记，标记线程和用户线程并发执行，并且收集各个Region的存活对象信息。</p><p>3.最终标记（remark STW）。标记那些在并发阶段发生变化的对象</p><p>4.复制/清除。（cleanup STW），这个阶段会优先对可回收空间较大的Region进行回收，即为Garbage first</p><p>G1采用的是每次只清理一部分而不是全部的Region的增量式清理，由此来保证每次GC停顿时间不会太长。</p><p>总结如下，G1是逻辑分代不是物理分代，需要知道回收的过程和停顿的阶段。此外还需要知道，G1算法允许通过JVM参数来设置Region大小，范围是1-32M（2的幂次），可以设置期望的最大停顿时间等</p>]]></content>
      
      
      <categories>
          
          <category> java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> jvm </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>JVM</title>
      <link href="/2020/04/29/%E5%AD%A6%E4%B9%A0/java/"/>
      <url>/2020/04/29/%E5%AD%A6%E4%B9%A0/java/</url>
      
        <content type="html"><![CDATA[<h2 id="1-jvm内存模型"><a href="#1-jvm内存模型" class="headerlink" title="1.jvm内存模型"></a>1.jvm内存模型</h2><h2 id="2-GC流程"><a href="#2-GC流程" class="headerlink" title="2.GC流程"></a>2.GC流程</h2><p>新生代创建对象，新生代区域不够的时候，会触发YGC,此时新生代会触发GC，对象进行清理。根据可达性算法对新生代空间的对象进行标记，通过复制算法进行新生代的对象回收。在多YGC过后，对象经过多次YGC后，然后就可以进行进行对象晋升，把该对象晋升到老年代。多次YGC之后，对象晋升老年代时候发现老年代的内存空间不足，会对老年代进行GC，通过</p><h2 id="3-常见的垃圾回收器"><a href="#3-常见的垃圾回收器" class="headerlink" title="3.常见的垃圾回收器"></a>3.常见的垃圾回收器</h2><p>CMS</p><p>ZGC</p><h2 id="4-G1收集器详解"><a href="#4-G1收集器详解" class="headerlink" title="4.G1收集器详解"></a>4.G1收集器详解</h2><p>G1垃圾收集器，取消了堆中年轻代和老年代的物理划分，但仍属于分代收集器。G1算法将堆划分为若干个Region区域。其中一部分作用于年轻代，一部分作用于老年代，还有一种专门用于存储大对象的分区。</p><p>几个概念</p><p>三色标记算法，白灰黑。白：对象没有被标记到，标记阶段结束，会被当做垃圾回收掉。灰：对象被标记了，但是它的filed还没有被标记完。黑:对象都别标记了，且它的filed也被标记完了。</p><p>新生代采用复制算法，并行进行收集，收集过程会STW</p><p>老年代回收时同时也会触发年轻代的回收，回收主要分为4个阶段：</p><p>1.初始标记（initial remark  STW）。它标记了从GC Root开始直接可达的对象</p><p>2.并发标记（concurrent mark）。这个标记阶段从GC Root开始对heap中的对象进行标记，标记线程和用户线程并发执行，并且收集各个Region的存活对象信息。</p><p>3.最终标记（remark STW）。标记那些在并发阶段发生变化的对象</p><p>4.复制/清除。（cleanup STW），这个阶段会优先对可回收空间较大的Region进行回收，即为Garbage first</p><p>G1采用的是每次只清理一部分而不是全部的Region的增量式清理，由此来保证每次GC停顿时间不会太长。</p><p>总结如下，G1是逻辑分代不是物理分代，需要知道回收的过程和停顿的阶段。此外还需要知道，G1算法允许通过JVM参数来设置Region大小，范围是1-32M（2的幂次），可以设置期望的最大停顿时间等</p>]]></content>
      
      
      <categories>
          
          <category> java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> jvm </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>个人总结</title>
      <link href="/2020/04/29/%E6%80%BB%E7%BB%93/%E5%B7%A5%E4%BD%9C%E6%80%BB%E7%BB%93-20200430/"/>
      <url>/2020/04/29/%E6%80%BB%E7%BB%93/%E5%B7%A5%E4%BD%9C%E6%80%BB%E7%BB%93-20200430/</url>
      
        <content type="html"><![CDATA[<h2 id="工作总结："><a href="#工作总结：" class="headerlink" title="工作总结：    "></a>工作总结：    </h2><p>五一活动上线完成，测试bug偏多，上线sql有问题。测试bug整体回顾中，发现小的需求遗漏较多。可能和自己心态有关，暂未发现良好的改进方向。可以考虑换个方式做整体设计，尤其是需求分析这块，要把所有的细节点都梳理到。</p><h2 id="工作反思："><a href="#工作反思：" class="headerlink" title="工作反思："></a>工作反思：</h2><h2 id="工作改进："><a href="#工作改进：" class="headerlink" title="工作改进："></a>工作改进：</h2><p>1.上线的sql文件中，所有的update语句和delete语句都删除掉！<br>2.验证上线文档文档的方式，就是把sql文件放到内网执行一遍，而不是直接看上线文档的sql。</p>]]></content>
      
      
      <categories>
          
          <category> 总结 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 工作总结 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>个人总结</title>
      <link href="/2020/04/29/%E6%80%BB%E7%BB%93/%E6%80%BB%E7%BB%93-2020/"/>
      <url>/2020/04/29/%E6%80%BB%E7%BB%93/%E6%80%BB%E7%BB%93-2020/</url>
      
        <content type="html"><![CDATA[<p>2020年已经过去了4个月了，现在就是整体梳理下java技术体系。</p>]]></content>
      
      
      <categories>
          
          <category> 总结 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 生活总结 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
